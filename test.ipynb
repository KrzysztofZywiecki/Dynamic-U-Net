{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from networks import DynamicUNet, LearnableScaleDynamicUNet\n",
    "from networks import dice_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#network = DynamicUNet(1, 2, [128, 256, 512], [128, 128, 64]).to(device)\n",
    "network = LearnableScaleDynamicUNet(1, 2, [128, 256, 512], 8, [(128, 4), (128, 2), (64, 1)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, ids, patch_folder=\"./segmentation/patches\", mask_folder=\"./segmentation/masks\", scale=1):\n",
    "        self.ids = ids\n",
    "        self.mask_folder = mask_folder\n",
    "        self.patch_folder = patch_folder\n",
    "        self.scale = scale\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    def __getitem__(self, index):\n",
    "        patch_path = os.path.join(self.patch_folder, \"org_{}.bmp\".format(self.ids[index]))\n",
    "        mask_path = os.path.join(self.mask_folder, \"mask_{}.bmp\".format(self.ids[index]))\n",
    "\n",
    "        patch = np.expand_dims(cv.imread(patch_path, cv.IMREAD_GRAYSCALE)/255.0, 0)\n",
    "        #patch = np.expand_dims(cv.resize(patch, None, fx=self.scale, fy=self.scale), 0)\n",
    "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
    "        mask = cv.resize(mask, None, fx=self.scale, fy=self.scale, interpolation=cv.INTER_NEAREST)\n",
    "\n",
    "        return torch.tensor(patch, dtype=torch.float), torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "ids = [ re.findall(\"[0-9]+\", name)[0] for name in os.listdir(\"./segmentation/patches\") ]\n",
    "\n",
    "train, test = train_test_split(ids, test_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss_fn = nn.CrossEntropyLoss()\n",
    "test_loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "plateau_window = 5  # Detect plateau if training doesn't progress after num epochs\n",
    "# plateau_lambda = 0.01 # Detect plateau if difference between current and best is less than lambda\n",
    "\n",
    "scales = [1/8, 1/4, 1/2, 1]\n",
    "\n",
    "losses = [ [] for _ in scales ]\n",
    "dice_scores = [ [] for _ in scales ]\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    breakthrough = 999\n",
    "    since = 0\n",
    "    side = 128 * scale\n",
    "\n",
    "    # train_dataset = SegmentationDataset(train, scale=scale)\n",
    "    # test_dataset = SegmentationDataset(test, scale=scale)\n",
    "    train_dataset = SegmentationDataset(train, scale=scale)\n",
    "    test_dataset = SegmentationDataset(test, scale=scale)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    while since != plateau_window:\n",
    "        # Training\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = network(X)\n",
    "            loss = train_loss_fn(x_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Testing\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            dice_score_ = 0\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device,), y.to(device)\n",
    "                x_hat = network(X)\n",
    "                loss += test_loss_fn(x_hat, y).item()\n",
    "                dice_score_ += dice_score(x_hat, y, reduction=\"sum\")\n",
    "            loss = loss / (len(test_dataset) * side * side ) \n",
    "            dice_score_ = dice_score_.detach().cpu().numpy() / len(test_dataset)\n",
    "            dice_scores[i].append(dice_score_)\n",
    "            since += 1\n",
    "            if loss < breakthrough:\n",
    "                breakthrough = loss\n",
    "                since=0\n",
    "            print(\"Loss:\", loss, \"Dice score:\", dice_score_)\n",
    "            losses[i].append(loss)\n",
    "    print(\"Epoch ended\")\n",
    "    network.use_higher_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "for loss in losses:\n",
    "    plt.plot(loss)\n",
    "plt.legend([1,2,3,4])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for dice in dice_scores:\n",
    "    plt.plot(dice)\n",
    "plt.legend([1,2,3,4])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "val = network(torch.randn((1, 1, 128, 128)).cuda()).cpu()\n",
    "\n",
    "make_dot(val.sum(), params=dict(list(network.named_parameters()))).render(\"torchviz3\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# temp_ = network.additional_mapper_classifiers[-2][\"mapper\"](torch.randn((5, 1, 128, 128)))\n",
    "\n",
    "# add_down_ = network.additional_downscale[-2](temp_)\n",
    "# downscaled_ = network.downscale(add_down_)\n",
    "\n",
    "# #-----------------------------------#\n",
    "\n",
    "# # temp = network.additional_mapper_classifiers[-1][\"mapper\"](torch.randn((5, 1, 64, 64)))\n",
    "\n",
    "# add_down = network.additional_downscale[-1](downscaled_)\n",
    "# downscaled = network.downscale(add_down)\n",
    "\n",
    "# y_hat = network.base_unet(downscaled)\n",
    "\n",
    "# upscaled = network.additional_upscale[-1][\"upsample_conv\"](y_hat)\n",
    "\n",
    "# sth = torch.cat([upscaled, add_down], dim=1)\n",
    "\n",
    "# res = network.additional_upscale[-1][\"conv_cell\"](sth)\n",
    "\n",
    "# # res = network.additional_mapper_classifiers[-1][\"classifier\"](res)\n",
    "\n",
    "# #-----------------------------------#\n",
    "\n",
    "# upscaled = network.additional_upscale[-2][\"upsample_conv\"](res)\n",
    "\n",
    "# sth = torch.cat([upscaled, add_down_], dim=1)\n",
    "\n",
    "# res = network.additional_upscale[-2][\"conv_cell\"](sth)\n",
    "\n",
    "# res = network.additional_mapper_classifiers[-2][\"classifier\"](res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from networks import dice_score\n",
    "\n",
    "tab1 = torch.randn((10, 2, 64, 64))\n",
    "tab2 = torch.randn((10, 64, 64)) > 0\n",
    "\n",
    "dice_score(tab1, tab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(network.additional_mapper_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(network.use_higher_layer() != True):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
